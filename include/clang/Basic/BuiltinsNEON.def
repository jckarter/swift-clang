//===--- BuiltinsNEON.def - NEON Builtin function database ------*- C++ -*-===//
//
//                     The LLVM Compiler Infrastructure
//
// This file is distributed under the University of Illinois Open Source
// License. See LICENSE.TXT for details.
//
//===----------------------------------------------------------------------===//
//
// This file defines the NEON-specific builtin function database.  Users of
// this file must define the BUILTIN macro to make use of this information.
//
//===----------------------------------------------------------------------===//

// The format of this database matches clang/Basic/Builtins.def.

#define GET_NEON_BUILTINS
#include "clang/Basic/arm_neon.inc"
#undef GET_NEON_BUILTINS

// The remaining intrinsics used to be automatically generated for ARM64 when
// it's front-end NEON implementation was entirely separare from the others, but
// during a transition period we're pasting them directly in here.

// Most are slight implementation differences that will be dropped entirely once
// we're using the AArch64/ARM header. However, there are some interesting
// cases:
//   + At the top are some intrinsics that AArch64 appears to lack
//     entirely. These will have to be implementted before final removal.
//   + The _high and _lane intrinsics should be considered for efficiency. In
//     some cases LLVM is inclined to only partially sink separated versions
//     into loops, which can create more work in the end.

// There appear to be no vcvtz intrinsics on AArch64. Probably an omission on
// that side.
BUILTIN(__builtin_neon_vcvtz_s32_v, "V8ScV8Sci", "n")
BUILTIN(__builtin_neon_vcvtzq_s32_v, "V16ScV16Sci", "n")
BUILTIN(__builtin_neon_vcvtzq_s64_v, "V16ScV16Sci", "n")
BUILTIN(__builtin_neon_vcvtz_u32_v, "V8ScV8Sci", "n")
BUILTIN(__builtin_neon_vcvtzq_u32_v, "V16ScV16Sci", "n")
BUILTIN(__builtin_neon_vcvtzq_u64_v, "V16ScV16Sci", "n")
BUILTIN(__builtin_neon_vcvtzd_s64_f64, "LLid", "n")
BUILTIN(__builtin_neon_vcvtzd_u64_f64, "ULLid", "n")
BUILTIN(__builtin_neon_vcvtzs_s32_f32, "if", "n")
BUILTIN(__builtin_neon_vcvtzs_u32_f32, "Uif", "n")

// AArch64 is missing vcgezd_u64 and vclezd_u64 intrinsics entirely.
BUILTIN(__builtin_neon_vcgezd_u64, "ULLiULLi", "n")
BUILTIN(__builtin_neon_vclezd_u64, "ULLiULLi", "n")

// AArch64 lacks vtblNq intrinsics
BUILTIN(__builtin_neon_vtbl1q_v, "V8ScV16ScV8Sci", "n")
BUILTIN(__builtin_neon_vtbl2q_v, "V8ScV16ScV16ScV8Sci", "n")
BUILTIN(__builtin_neon_vtbl3q_v, "V8ScV16ScV16ScV16ScV8Sci", "n")
BUILTIN(__builtin_neon_vtbl4q_v, "V8ScV16ScV16ScV16ScV16ScV8Sci", "n")
BUILTIN(__builtin_neon_vtbx1q_v, "V8ScV8ScV16ScV8Sci", "n")
BUILTIN(__builtin_neon_vtbx2q_v, "V8ScV8ScV16ScV16ScV8Sci", "n")
BUILTIN(__builtin_neon_vtbx3q_v, "V8ScV8ScV16ScV16ScV16ScV8Sci", "n")
BUILTIN(__builtin_neon_vtbx4q_v, "V8ScV8ScV16ScV16ScV16ScV16ScV8Sci", "n")

// AArch64 has no vusqadd intrinsics
BUILTIN(__builtin_neon_vusqadd_v, "V8ScV8ScV8Sci", "n")
BUILTIN(__builtin_neon_vusqaddq_v, "V16ScV16ScV16Sci", "n")

// vabal is implemented as separate vabdl & addition on AArch64.
BUILTIN(__builtin_neon_vabal_v, "V16ScV16ScV8ScV8Sci", "n")
BUILTIN(__builtin_neon_vabdl_v, "V16ScV8ScV8Sci", "n")

// AArch64 uses a vget_lane and vset_lane pair.
BUILTIN(__builtin_neon_vcopyq_lane_v, "V16ScV16SciV16Scii", "n")

// AArch64 uses __builtin_neon_vcvtx_f32_v for this. Simple name choice
// difference.
BUILTIN(__builtin_neon_vcvtx_f32_f64, "V8ScV16Sci", "n")

// AArch64 uses "a / b" for this, unsurprisingly.
BUILTIN(__builtin_neon_vdiv_v, "V8ScV8ScV8Sci", "n")
BUILTIN(__builtin_neon_vdivq_v, "V16ScV16ScV16Sci", "n")

// AArch64 uses shufflevectors for this.
BUILTIN(__builtin_neon_vdupb_lane_s8, "ScV8Sci", "n")
BUILTIN(__builtin_neon_vdupb_lane_u8, "UcV8Sci", "n")
BUILTIN(__builtin_neon_vdupd_lane_s64, "LLiV1LLii", "n")
BUILTIN(__builtin_neon_vdupd_lane_u64, "ULLiV1LLii", "n")
BUILTIN(__builtin_neon_vduph_lane_s16, "sV4si", "n")
BUILTIN(__builtin_neon_vduph_lane_u16, "UsV4si", "n")
BUILTIN(__builtin_neon_vdups_lane_s32, "iV2ii", "n")
BUILTIN(__builtin_neon_vdups_lane_u32, "UiV2ii", "n")
BUILTIN(__builtin_neon_vdup_lane_f64, "dV8Sci", "n")

// AArch64 redirects to vfma_lane here (with a sign flip).
BUILTIN(__builtin_neon_vfms_lane_v, "V8ScV8ScV8ScV8Scii", "n")
BUILTIN(__builtin_neon_vfmsq_lane_v, "V16ScV16ScV16ScV8Scii", "n")

// Somehow AArch64 has ended up with vget_lane_iN here instead of separate
// signed & unsigned versions. A definite improvement.
BUILTIN(__builtin_neon_vget_lane_s8, "ScV8Sci", "n")
BUILTIN(__builtin_neon_vget_lane_s16, "sV4si", "n")
BUILTIN(__builtin_neon_vget_lane_s32, "iV2ii", "n")
BUILTIN(__builtin_neon_vget_lane_s64, "LLiV1LLii", "n")
BUILTIN(__builtin_neon_vget_lane_u8, "UcV8Sci", "n")
BUILTIN(__builtin_neon_vget_lane_u16, "UsV4si", "n")
BUILTIN(__builtin_neon_vget_lane_u32, "UiV2ii", "n")
BUILTIN(__builtin_neon_vget_lane_u64, "ULLiV1LLii", "n")
BUILTIN(__builtin_neon_vget_lane_p8, "UcV8Sci", "n")
BUILTIN(__builtin_neon_vget_lane_p16, "UsV4si", "n")
BUILTIN(__builtin_neon_vgetq_lane_s8, "ScV16Sci", "n")
BUILTIN(__builtin_neon_vgetq_lane_s16, "sV8si", "n")
BUILTIN(__builtin_neon_vgetq_lane_s32, "iV4ii", "n")
BUILTIN(__builtin_neon_vgetq_lane_s64, "LLiV2LLii", "n")
BUILTIN(__builtin_neon_vgetq_lane_u8, "UcV16Sci", "n")
BUILTIN(__builtin_neon_vgetq_lane_u16, "UsV8si", "n")
BUILTIN(__builtin_neon_vgetq_lane_u32, "UiV4ii", "n")
BUILTIN(__builtin_neon_vgetq_lane_u64, "ULLiV2LLii", "n")
BUILTIN(__builtin_neon_vgetq_lane_p8, "UcV16Sci", "n")
BUILTIN(__builtin_neon_vgetq_lane_p16, "UsV8si", "n")

// AArch64 uses a vmulx & shuffle for the lane.
BUILTIN(__builtin_neon_vmulx_lane_v, "V8ScV8ScV8Scii", "n")
BUILTIN(__builtin_neon_vmulxq_lane_v, "V16ScV16ScV16Scii", "n")

// AArch64 uses a vqdmull[hs] and a vget_lane here.
BUILTIN(__builtin_neon_vqdmullh_lane_s16, "isV8si", "n")
BUILTIN(__builtin_neon_vqdmulls_lane_s32, "LLiiV4ii", "n")

// AArch64 doesn't have vrndz intrinsics
BUILTIN(__builtin_neon_vrndz_v, "V8ScV8Sci", "n")
BUILTIN(__builtin_neon_vrndzq_v, "V16ScV16Sci", "n")

// AArch64 uses __builtin_neon_vqshl_v
BUILTIN(__builtin_neon_vqrshl_s64, "LLiLLiLLi", "n")
BUILTIN(__builtin_neon_vqrshl_u64, "ULLiULLiULLi", "n")
BUILTIN(__builtin_neon_vqshl_s64, "LLiLLiLLi", "n")
BUILTIN(__builtin_neon_vqshl_u64, "ULLiULLiULLi", "n")
BUILTIN(__builtin_neon_vrshl_s64, "LLiLLiLLi", "n")
BUILTIN(__builtin_neon_vrshl_u64, "ULLiULLiULLi", "n")
BUILTIN(__builtin_neon_vshl_s64, "LLiLLiLLi", "n")
BUILTIN(__builtin_neon_vshl_u64, "ULLiULLiULLi", "n")

// AArch64 casts back & forth to s16.
BUILTIN(__builtin_neon_vset_lane_f16, "V4sUsV4si", "n")
BUILTIN(__builtin_neon_vsetq_lane_f16, "V8sUsV8si", "n")

// AArch64 uses a pure shuffle for these
BUILTIN(__builtin_neon_vtrn1_v, "V8ScV8ScV8Sci", "n")
BUILTIN(__builtin_neon_vtrn1q_v, "V16ScV16ScV16Sci", "n")
BUILTIN(__builtin_neon_vtrn2_v, "V8ScV8ScV8Sci", "n")
BUILTIN(__builtin_neon_vtrn2q_v, "V16ScV16ScV16Sci", "n")
BUILTIN(__builtin_neon_vuzp1_v, "V8ScV8ScV8Sci", "n")
BUILTIN(__builtin_neon_vuzp1q_v, "V16ScV16ScV16Sci", "n")
BUILTIN(__builtin_neon_vuzp2_v, "V8ScV8ScV8Sci", "n")
BUILTIN(__builtin_neon_vuzp2q_v, "V16ScV16ScV16Sci", "n")
BUILTIN(__builtin_neon_vzip1_v, "V8ScV8ScV8Sci", "n")
BUILTIN(__builtin_neon_vzip1q_v, "V16ScV16ScV16Sci", "n")
BUILTIN(__builtin_neon_vzip2_v, "V8ScV8ScV8Sci", "n")
BUILTIN(__builtin_neon_vzip2q_v, "V16ScV16ScV16Sci", "n")

// AArch64 uses the base intrinsics in combination with "vget_high" and
// "vcombine" intrinsics.
BUILTIN(__builtin_neon_vabal_high_v, "V16ScV16ScV16ScV16Sci", "n")
BUILTIN(__builtin_neon_vabdl_high_v, "V16ScV16ScV16Sci", "n")
BUILTIN(__builtin_neon_vaddhn_high_v, "V16ScV8ScV16ScV16Sci", "n")
BUILTIN(__builtin_neon_vaddw_high_v, "V16ScV16ScV16Sci", "n")
BUILTIN(__builtin_neon_vcvtx_high_f32_f64, "V16ScV8ScV16Sci", "n")
BUILTIN(__builtin_neon_vcvt_high_f32_f64, "V16ScV8ScV16Sci", "n")
BUILTIN(__builtin_neon_vcvt_high_f64_f32, "V16ScV16Sci", "n")
BUILTIN(__builtin_neon_vmovn_high_v, "V16ScV8ScV16Sci", "n")
BUILTIN(__builtin_neon_vqdmlal_high_v, "V16ScV16ScV16ScV16Sci", "n")
BUILTIN(__builtin_neon_vqdmlsl_high_v, "V16ScV16ScV16ScV16Sci", "n")
BUILTIN(__builtin_neon_vqdmull_high_v, "V16ScV16ScV16Sci", "n")
BUILTIN(__builtin_neon_vqmovn_high_v, "V16ScV8ScV16Sci", "n")
BUILTIN(__builtin_neon_vqmovun_high_v, "V16ScV8ScV16Sci", "n")
BUILTIN(__builtin_neon_vqrshrn_high_n_v, "V16ScV8ScV16Scii", "n")
BUILTIN(__builtin_neon_vqrshrun_high_n_v, "V16ScV8ScV16Scii", "n")
BUILTIN(__builtin_neon_vqshrn_high_n_v, "V16ScV8ScV16Scii", "n")
BUILTIN(__builtin_neon_vqshrun_high_n_v, "V16ScV8ScV16Scii", "n")
BUILTIN(__builtin_neon_vraddhn_high_v, "V16ScV8ScV16ScV16Sci", "n")
BUILTIN(__builtin_neon_vrshrn_high_n_v, "V16ScV8ScV16Scii", "n")
BUILTIN(__builtin_neon_vrsubhn_high_v, "V16ScV8ScV16ScV16Sci", "n")
BUILTIN(__builtin_neon_vshll_high_n_v, "V16ScV16Scii", "n")
BUILTIN(__builtin_neon_vshrn_high_n_v, "V16ScV8ScV16Scii", "n")
BUILTIN(__builtin_neon_vsubhn_high_v, "V16ScV8ScV16ScV16Sci", "n")
BUILTIN(__builtin_neon_vsubl_high_v, "V16ScV16ScV16Sci", "n")
BUILTIN(__builtin_neon_vsubw_high_v, "V16ScV16ScV16Sci", "n")

#undef BUILTIN
